+++

author = "Chris Short"
categories = ["Weekly", "Newsletter", "DevOps News", "Cloud Native News", "2021"]
date = 2021-09-05T07:00:00Z
description = [""]
draft = false
slug = "233"
tags = []
title = ""

+++

I spent most of the week in a deteriorated state. Getting over the 12 injections last Friday took much longer than expected. It still amazes me how much work I can do with a disability, medications that slow me down, and a lack of sleep (Max started Kindergarten this week).

In a way, this is a lot like our systems, overtaxed by the increasing number of people using them. Ready to both be upgraded by an admin and taken down by a deluge of traffic at the same time (or worse, the opposite). Running along in a less than optimal state is pretty optimal for a lot of workloads. Sure, specific workloads will need certain kinds of hardware, and the software varies in those spaces. But, most of us are still using an abstraction of an abstraction of an abstraction (of an abstraction).

Like a top starting to lose its grip on centrifugal force, our systems run fine until they don't. Now, more than ever, we need to know how the systems are performing. What caused the slowdown? What sent the system sliding off the table into oblivion? Will it be able to be spinning like a top again soon? What do you do to pick it back up and having it moving like the top in Inception? All these questions are answered by the same question: How do we know if we're doing the right thing?

If you're doing the right things, the system will bounce back resiliently, knowing that maybe that AZ is having a bad day, the direct connect *isn't* the fastest route anymore due to an upstream provider mistake, or the system is in a state its never experienced before. If you're doing the right things, downtime is minimal. Services impacted are few. Dollars lost are low. This reminds me, if you don't know how much your organization is losing by any given system outage, you might not be doing the right thing.

But, how the team moves forward is a series of steps that eventually lead to the right thing to do to fix the system. If you're ever stuck troubleshooting, ask yourself, "How do we do what's right here?" Reset the situation in your mind. Find the point of failure by starting from the closest thing to the failure and eliminating what's working from the list. Verify they're working. Trust but verify. You can get to the right thing by process of elimination sometimes too.

## People

PEOPLE

[Declarative Cloud Infrastructure Management with Terraform](https://www.linode.com/content/declarative-cloud-infrastructure-management-terraform-linode/?utm_source=devopsish&utm_medium=newsletter_sponsorship&utm_campaign=newsletter_sponsorship-tldr-terraform&utm_content=ebook-terraform&utm_term=)  
100 Million Downloads and Over 5,000 Ecosystem Add-Ons later, Hashicorp has released the 1.0 version of Terraform. This eBook and audiobook will help you understand the underlying concepts of this infrastructure as a code tool and how it can be a significant resource when your cloud infrastructure hits critical mass. *SPONSORED*

PEOPLE

## Process

PROCESS

[Infrastructure as Code Automation for Terrafrom and GitOps workflows](https://www.env0.com/infrastructure-as-code-automation?utm_campaign=devopsish&utm_source=nativeads&utm_medium=newsletter)  
Code, No Manual Processes. Automate Terraform tasks, reduce errors and drifts, improve security and auditability of your infrastructure. env0 automates and simplifies the provisioning of cloud deployments for Terraform, Terragrunt and GitOps workflows. *SPONSORED*

PROCESS

## Tools

TOOLS

[Manage incidents directly from Slack üßë‚Äçüöí](https://consuming-macrospore.herokuapp.com/b?y=49q24eh2c4r3ce1gcoo3echi65h62opj74rjcdpic9ij6e3571im4dpocch2o8ji48t24q3keho76ehf5tp6urrkdhsisqbf5svnat3dbtpmutbicdijqrj5etpmopbkehin49j1dlo3mtbkdlfmqpb4d5qmqfb4clr6us3jd5pmg8g=?utm_source=devopsish&utm_campaign=233&utm_medium=newsletter)  
Rootly helps automate the tedious manual work like creating incident channels, searching for runbooks, documenting the postmortem timeline, and more. Teams sized 20 to 2000 manage hundreds of incidents daily and save thousands of engineering hours a year within Rootly. Get started in <5min or book a demo to learn more and get Starbucks ‚òï on us! *SPONSORED*

TOOLS

## DevOps'ish Tweet of the Week

[![Jaana Dogan „É§„Éä „Éâ„Ç¨„É≥ (@rakyll) on Twitter: "Hard skills are hard, soft skills are harder."](/images/233-devopsish-tweet-of-the-week.png)](https://twitter.com/rakyll/status/1430696443044532228)

Want more? Be sure to check out the [notes from this week's issue](https://devopsish.com/233/notes/) to see what didn't make it to the newsletter but are still worth your time.
